{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-92627146f48a>:14: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "TF with GPU: True\n",
      "Torch with GPU: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: camperko (use `wandb login --relogin` to force relogin)\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import gym\n",
    "\n",
    "import tensorflow as tf\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "from torch.distributions import Beta\n",
    "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print('TF with GPU: ' + str(tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)))\n",
    "print('Torch with GPU: {}'.format(torch.cuda.is_available()))\n",
    "wandb.login()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"num_episodes\": 1500,\n",
    "    \"num_epochs\": 2000,\n",
    "    \"image_batch\": 4,\n",
    "    \"lr\": 1e-3,\n",
    "    \"logging_interval\": 5,\n",
    "    \"render\": True,\n",
    "    \"action_count\": 4,\n",
    "    \"memory_cap\": 2560,\n",
    "    \"ppo_batch\": 32,\n",
    "    \"ppo_epoch\": 10,\n",
    "    \"loss_clip\": 0.1,\n",
    "    \"gamma_discount\": 0.99,\n",
    "    \"render_interval\": 50\n",
    "}\n",
    "\n",
    "action_type = np.dtype([\n",
    "    ('last_state', np.float64, (config['image_batch'], 96, 96)),\n",
    "    ('curr_state', np.float64, (config['image_batch'], 96, 96)),\n",
    "    ('act', np.float64, (3,)),\n",
    "    ('act_prob', np.float64),\n",
    "    ('reward', np.float64)\n",
    "])\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[..., :], [0.299, 0.587, 0.114]) / 128. - 1."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(config['image_batch'], 8, kernel_size=(4, 4), stride=(2,2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, kernel_size=(3, 3), stride=(2,2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2,2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(2,2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1,1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1,1)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.v = nn.Sequential(\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.alpha_head = nn.Sequential(\n",
    "            nn.Linear(64, 3),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        self.beta_head = nn.Sequential(\n",
    "            nn.Linear(64, 3),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        self.apply(self._weights_init)\n",
    "\n",
    "    @staticmethod\n",
    "    def _weights_init(m):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain('relu'))\n",
    "            nn.init.constant_(m.bias, 0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x).view(-1, 256)\n",
    "        v = self.v(x)\n",
    "        x = self.fc(x)\n",
    "        alpha = self.alpha_head(x) + 1\n",
    "        beta = self.beta_head(x) + 1\n",
    "\n",
    "        return (alpha, beta), v"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class Agent():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.net = Net().double().to(device)\n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=config['lr'])\n",
    "\n",
    "        self.memory = np.empty(config['memory_cap'], dtype=action_type)\n",
    "        self.memory_index = 0\n",
    "\n",
    "    def choose_action(self, curr_state):\n",
    "        with torch.no_grad():\n",
    "            action, _ = self.net(torch.from_numpy(curr_state).double().to(device).unsqueeze(0))\n",
    "        distribution = Beta(action[0], action[1])\n",
    "        act = distribution.sample()\n",
    "        act_prob = distribution.log_prob(act).sum(dim=1)\n",
    "        return act.squeeze().cpu().numpy(), act_prob.item()\n",
    "\n",
    "    def insert_into_memory(self, memory_sample):\n",
    "        self.memory[self.memory_index] = memory_sample\n",
    "        self.memory_index += 1\n",
    "        if self.memory_index == config['memory_cap']:\n",
    "            self.memory_index = 0\n",
    "\n",
    "    def ready_for_update(self):\n",
    "        return True if self.memory_index == 0 else False\n",
    "\n",
    "    def update_self(self):\n",
    "        last_state = torch.tensor(self.memory['last_state'], dtype=torch.double).to(device)\n",
    "        curr_state = torch.tensor(self.memory['curr_state'], dtype=torch.double).to(device)\n",
    "        action = torch.tensor(self.memory['act'], dtype=torch.double).to(device)\n",
    "        rew = torch.tensor(self.memory['reward'], dtype=torch.double).to(device).view(-1, 1)\n",
    "        action_prob = torch.tensor(self.memory['act_prob'], dtype=torch.double).to(device).view(-1, 1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            target_v = rew + config['gamma_discount'] * self.net(curr_state)[1]\n",
    "            adv = target_v - self.net(last_state)[1]\n",
    "\n",
    "        for _ in range(config['ppo_epoch']):\n",
    "            for index in BatchSampler(SubsetRandomSampler(range(config['memory_cap'])), config['ppo_batch'], False):\n",
    "                alpha, beta = self.net(last_state[index])[0]\n",
    "                dist = Beta(alpha, beta)\n",
    "                a_logp = dist.log_prob(action[index]).sum(dim=1, keepdim=True)\n",
    "                ratio = torch.exp(a_logp - action_prob[index])\n",
    "\n",
    "                surr1 = ratio * adv[index]\n",
    "                surr2 = torch.clamp(ratio, 1.0 - config['loss_clip'], 1.0 + config['loss_clip']) * adv[index]\n",
    "                action_loss = -torch.min(surr1, surr2).mean()\n",
    "                value_loss = F.smooth_l1_loss(self.net(last_state[index])[1], target_v[index])\n",
    "                loss = action_loss + 2. * value_loss\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programming\\NSIETE\\Assignment\\NSIETE-assignment_3\\venv\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "wandb: wandb version 0.10.30 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.27<br/>\n                Syncing run <strong style=\"color:#cdcd00\">dashing-frog-21</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/camperko/car-racing\" target=\"_blank\">https://wandb.ai/camperko/car-racing</a><br/>\n                Run page: <a href=\"https://wandb.ai/camperko/car-racing/runs/1xigo2ov\" target=\"_blank\">https://wandb.ai/camperko/car-racing/runs/1xigo2ov</a><br/>\n                Run data is saved locally in <code>C:\\Programming\\NSIETE\\Assignment\\NSIETE-assignment_3\\wandb\\run-20210510_225247-1xigo2ov</code><br/><br/>\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1107..1388 -> 281-tiles track\n",
      "Total reward for episode 0 is 78.57142857142861\n",
      "Track generation: 991..1250 -> 259-tiles track\n",
      "Track generation: 1035..1302 -> 267-tiles track\n",
      "Track generation: 1236..1549 -> 313-tiles track\n",
      "Track generation: 1048..1314 -> 266-tiles track\n",
      "Track generation: 1176..1474 -> 298-tiles track\n",
      "Total reward for episode 5 is 74.07407407407405\n",
      "Track generation: 969..1220 -> 251-tiles track\n",
      "Track generation: 1209..1515 -> 306-tiles track\n",
      "Track generation: 1075..1348 -> 273-tiles track\n",
      "Track generation: 1160..1454 -> 294-tiles track\n",
      "Updating agent\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CarRacing-v0')\n",
    "reward_threshold = env.spec.reward_threshold\n",
    "env.close()\n",
    "\n",
    "agent = Agent()\n",
    "\n",
    "run = wandb.init(project=\"car-racing\")\n",
    "\n",
    "wandb.config.update(config)\n",
    "\n",
    "total_rewards = deque(maxlen=100)\n",
    "reward_mean = 0\n",
    "\n",
    "for i_episode in range(config['num_episodes']):\n",
    "    env = gym.make('CarRacing-v0')\n",
    "    observation = env.reset()\n",
    "    old_state = [rgb2gray(observation)] * config['image_batch']\n",
    "    new_state = [rgb2gray(observation)] * config['image_batch']\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    reward_history = deque(maxlen=100)\n",
    "\n",
    "    for _ in range(config['num_epochs']):\n",
    "        if config['render'] and i_episode % config['render_interval'] == 0 and i_episode != 0:\n",
    "            env.render()\n",
    "\n",
    "        todo_action, todo_action_prob = agent.choose_action(np.array(new_state))\n",
    "\n",
    "        todo_action = todo_action * np.array([2., 1., 1.]) + np.array([-1., 0., 0.])\n",
    "\n",
    "        inner_reward = 0\n",
    "        for i in range(config['action_count']):\n",
    "            observation, reward, done, _ = env.step(todo_action)\n",
    "\n",
    "            if np.mean(observation[:, :, 1]) > 185.0:\n",
    "                reward -= 0.05\n",
    "\n",
    "            reward += 100 if done else 0\n",
    "\n",
    "            inner_reward += reward\n",
    "\n",
    "            reward_history.append(reward)\n",
    "            if done or np.mean(reward_history) <= -0.1:\n",
    "                break\n",
    "\n",
    "        new_state.pop(0)\n",
    "        new_state.append(rgb2gray(observation))\n",
    "\n",
    "        agent.insert_into_memory((np.array(old_state), np.array(new_state), todo_action, todo_action_prob, inner_reward))\n",
    "        if agent.ready_for_update():\n",
    "            print('Updating agent')\n",
    "            agent.update_self()\n",
    "\n",
    "        old_state.pop(0)\n",
    "        old_state.append(rgb2gray(observation))\n",
    "\n",
    "        total_reward += inner_reward\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    total_rewards.append(total_reward)\n",
    "    wandb.log({\"episode_reward\": total_reward}, commit=True)\n",
    "    reward_mean = np.mean(total_rewards)\n",
    "    if i_episode % config['logging_interval'] == 0:\n",
    "        print('Total reward for episode {} is {}'.format(i_episode, total_reward))\n",
    "    if reward_mean >= reward_threshold:\n",
    "        print('Env solved in {} episodes'.format(i_episode))\n",
    "        break\n",
    "\n",
    "    env.close()\n",
    "\n",
    "if reward_mean < reward_threshold:\n",
    "    print('Env not solved in {} episodes'.format(config['num_episodes']))\n",
    "    print('Mean of score for last 100 runs is {}'.format(reward_mean))\n",
    "\n",
    "\n",
    "run.finish()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programming\\NSIETE\\Assignment\\NSIETE-assignment_3\\venv\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1236..1549 -> 313-tiles track\n",
      "Action from net\n",
      "(tensor([[1.7263, 1.7781, 1.7562]], device='cuda:0', dtype=torch.float64), tensor([[1.7590, 1.7411, 1.6706]], device='cuda:0', dtype=torch.float64))\n",
      "Distribution from action\n",
      "Beta()\n",
      "Sample action\n",
      "tensor([[0.7013, 0.7197, 0.5666]], device='cuda:0', dtype=torch.float64)\n",
      "Returned action\n",
      "[0.70132948 0.71973825 0.56657877]\n",
      "Action from net\n",
      "(tensor([[1.7381, 1.7578, 1.7591]], device='cuda:0', dtype=torch.float64), tensor([[1.7647, 1.7489, 1.6763]], device='cuda:0', dtype=torch.float64))\n",
      "Distribution from action\n",
      "Beta()\n",
      "Sample action\n",
      "tensor([[0.2835, 0.4353, 0.6308]], device='cuda:0', dtype=torch.float64)\n",
      "Returned action\n",
      "[0.28346383 0.43531157 0.63079592]\n",
      "Action from net\n",
      "(tensor([[1.7155, 1.7353, 1.7545]], device='cuda:0', dtype=torch.float64), tensor([[1.7564, 1.7567, 1.6804]], device='cuda:0', dtype=torch.float64))\n",
      "Distribution from action\n",
      "Beta()\n",
      "Sample action\n",
      "tensor([[0.8580, 0.6637, 0.3153]], device='cuda:0', dtype=torch.float64)\n",
      "Returned action\n",
      "[0.85802081 0.66368758 0.31532258]\n",
      "Action from net\n",
      "(tensor([[1.7353, 1.7613, 1.7416]], device='cuda:0', dtype=torch.float64), tensor([[1.7325, 1.7087, 1.6780]], device='cuda:0', dtype=torch.float64))\n",
      "Distribution from action\n",
      "Beta()\n",
      "Sample action\n",
      "tensor([[0.1634, 0.9115, 0.3213]], device='cuda:0', dtype=torch.float64)\n",
      "Returned action\n",
      "[0.16337182 0.91147249 0.32131141]\n",
      "Action from net\n",
      "(tensor([[1.7321, 1.7638, 1.7551]], device='cuda:0', dtype=torch.float64), tensor([[1.7630, 1.7220, 1.6881]], device='cuda:0', dtype=torch.float64))\n",
      "Distribution from action\n",
      "Beta()\n",
      "Sample action\n",
      "tensor([[0.6769, 0.5336, 0.3770]], device='cuda:0', dtype=torch.float64)\n",
      "Returned action\n",
      "[0.67685887 0.533554   0.3770181 ]\n"
     ]
    }
   ],
   "source": [
    "agent2 = Agent()\n",
    "\n",
    "env = gym.make('CarRacing-v0')\n",
    "\n",
    "observation = env.reset()\n",
    "\n",
    "old_state = [rgb2gray(observation)] * config['image_batch']\n",
    "new_state = [rgb2gray(observation)] * config['image_batch']\n",
    "done = False\n",
    "for i in range(5):\n",
    "    env.render()\n",
    "    todo_action, todo_action_prob = agent2.choose_action(np.asarray(new_state))\n",
    "\n",
    "    for i in range(config['action_count']):\n",
    "        observation, reward, done, _ = env.step(todo_action)\n",
    "\n",
    "        if i != config['action_count'] - 1:\n",
    "            del observation\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    new_state.pop(0)\n",
    "    new_state.append(rgb2gray(observation))\n",
    "\n",
    "    old_state.pop(0)\n",
    "    old_state.append(rgb2gray(observation))\n",
    "\n",
    "    # del observation\n",
    "    if done:\n",
    "        break\n",
    "env.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(-1.0, 1.0, (3,), float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programming\\NSIETE\\Assignment\\NSIETE-assignment_3\\venv\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CarRacing-v0')\n",
    "\n",
    "print(env.action_space)\n",
    "\n",
    "env.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-93414546",
   "language": "python",
   "display_name": "PyCharm (NSIETE-assignment_3)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}